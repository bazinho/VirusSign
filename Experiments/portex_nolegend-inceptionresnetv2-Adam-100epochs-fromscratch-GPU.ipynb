{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold                              \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as colormap\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagedir = \"Datasets/ByFamilyPortexNoLegend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\tFamily:         allaple\tNumber of images: 362\n",
      "Label: 1\tFamily:           alman\tNumber of images: 325\n",
      "Label: 2\tFamily:          autoit\tNumber of images: 261\n",
      "Label: 3\tFamily:            daws\tNumber of images: 466\n",
      "Label: 4\tFamily:            delf\tNumber of images: 359\n",
      "Label: 5\tFamily:         gamarue\tNumber of images: 259\n",
      "Label: 6\tFamily:          ibryte\tNumber of images: 347\n",
      "Label: 7\tFamily:          loring\tNumber of images: 285\n",
      "Label: 8\tFamily:          mydoom\tNumber of images: 578\n",
      "Label: 9\tFamily:          qukart\tNumber of images: 253\n",
      "Label:10\tFamily:          ramnit\tNumber of images: 506\n",
      "Label:11\tFamily:          sality\tNumber of images: 1401\n",
      "Label:12\tFamily:          simbot\tNumber of images: 1148\n",
      "Label:13\tFamily:       softpulse\tNumber of images: 912\n",
      "Label:14\tFamily:          viking\tNumber of images: 183\n",
      "Label:15\tFamily:         virlock\tNumber of images: 373\n",
      "Label:16\tFamily:          vobfus\tNumber of images: 405\n",
      "Label:17\tFamily:          wapomi\tNumber of images: 345\n",
      "Label:18\tFamily:            zbot\tNumber of images: 863\n",
      "Label:19\tFamily:          zegost\tNumber of images: 505\n",
      "Processing images ...\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(imagedir)  # the parent folder with sub-folders\n",
    "\n",
    "# Get number of samples per family\n",
    "list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names\n",
    "no_imgs = []  # No. of samples per family\n",
    "for i in range(len(list_fams)):\n",
    "    os.chdir(list_fams[i])\n",
    "    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png'\n",
    "    no_imgs.append(len1)\n",
    "    os.chdir('..')\n",
    "num_samples = np.sum(no_imgs)  # total number of all samples\n",
    "\n",
    "# Compute the labels\n",
    "y = np.zeros(num_samples)\n",
    "pos = 0\n",
    "label = 0\n",
    "for i in no_imgs:\n",
    "    print (\"Label:%2d\\tFamily: %15s\\tNumber of images: %d\" % (label, list_fams[label], i))\n",
    "    for j in range(i):\n",
    "        y[pos] = label\n",
    "        pos += 1\n",
    "    label += 1\n",
    "num_classes = label\n",
    "\n",
    "# Compute the features\n",
    "width, height,channels = (224,224,3)\n",
    "X = np.zeros((num_samples, width, height, channels))\n",
    "cnt = 0\n",
    "list_paths = [] # List of image paths\n",
    "print(\"Processing images ...\")\n",
    "for i in range(len(list_fams)):\n",
    "    for img_file in glob.glob(list_fams[i]+'/*.png'):\n",
    "        #print(\"[%d] Processing image: %s\" % (cnt, img_file))\n",
    "        list_paths.append(os.path.join(os.getcwd(),img_file))\n",
    "        img = image.load_img(img_file, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        X[cnt] = x\n",
    "        cnt += 1\n",
    "print(\"Images processed: %d\" %(cnt))\n",
    "\n",
    "os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding classes (y) into integers (y_encoded) and then generating one-hot-encoding (Y)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "Y = np_utils.to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create stratified k-fold subsets                                                                                                                                        \n",
    "kfold = 10  # no. of folds                                                                 \n",
    "skf = StratifiedKFold(kfold, shuffle=True,random_state=1)\n",
    "skfind = [None] * kfold  # skfind[i][0] -> train indices, skfind[i][1] -> test indices\n",
    "cnt = 0                                              \n",
    "for index in skf.split(X, y):         \n",
    "    skfind[cnt] = index                                                 \n",
    "    cnt += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the model from scratch\n",
    "num_epochs=100\n",
    "image_shape = (224, 224, 3)                                                                                                                                                                                                                                                                                            \n",
    "history = []\n",
    "checkpointer = ModelCheckpoint(filepath='weights-portex_nolegend-inceptionresnetv2-Adam-%depochs-fromscratch.h5' %(num_epochs), monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=True, mode='auto')\n",
    "callbacks_list = [checkpointer]\n",
    "conf_mat = np.zeros((len(list_fams),len(list_fams))) # Initializing the Confusion Matrix\n",
    "\n",
    "model = InceptionResNetV2(weights=None, input_shape=image_shape, include_top=True, classes=num_classes)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "init_weights = model.get_weights()\n",
    "\n",
    "for i in range(kfold):\n",
    "    train_indices = skfind[i][0]\n",
    "    test_indices = skfind[i][1]\n",
    "    X_train = X[train_indices]\n",
    "    Y_train = Y[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    Y_test = Y[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    model.set_weights(init_weights)\n",
    "\n",
    "    start = time.time()\n",
    "    h = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=num_epochs, batch_size=32, verbose=1, callbacks=callbacks_list)\n",
    "    end = time.time()\n",
    "    history.append(h)\n",
    "    \n",
    "    y_prob = model.predict(X_test, verbose=1)  # Testing\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    print(\"[%d] Test acurracy: %.4f (%.4f s)\" %(i,accuracy_score(y_test,y_pred),end-start))\n",
    "    \n",
    "    cm = confusion_matrix(y_test,y_pred)  # Compute confusion matrix for this fold\n",
    "    conf_mat = conf_mat + cm  # Compute global confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the average accuracy\n",
    "avg_acc = np.trace(conf_mat)/np.sum(conf_mat)\n",
    "print(\"Average acurracy: %.4f\" %(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_acc(history):\n",
    "    figure = plt.gcf()\n",
    "    figure.set_size_inches(14, 6)\n",
    "    ax = plt.subplot()\n",
    "    #plt.title('Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    colors = iter(colormap.gist_rainbow(np.linspace(0, 1, len(history))))\n",
    "    for i in range(len(history)):\n",
    "        color=next(colors)\n",
    "        plt.plot(history[i].history['acc'], label='Train '+str(i), color=color, linestyle = 'solid', linewidth=2.0)\n",
    "        plt.plot(history[i].history['val_acc'], label='Test '+str(i), color=color, linestyle = 'dotted', linewidth=2.0)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,0.0,1.0))\n",
    "    plt.legend()\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    figure = plt.gcf()\n",
    "    figure.set_size_inches(14, 6)\n",
    "    ax = plt.subplot()\n",
    "    #plt.title('Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    colors = iter(colormap.gist_rainbow(np.linspace(0, 1, len(history))))\n",
    "    for i in range(len(history)):\n",
    "        color=next(colors)\n",
    "        plt.plot(history[i].history['loss'], label='Train '+str(i), color=color, linestyle = 'solid', linewidth=2.0)\n",
    "        plt.plot(history[i].history['val_loss'], label='Test '+str(i), color=color, linestyle = 'dotted', linewidth=2.0)\n",
    "    plt.legend()\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "print(\"Plotting the confusion matrix\")\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(20, 12)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(conf_mat, cbar=False, annot=True, square=True,\n",
    "                 fmt='.0f', annot_kws={'size': 10}, linewidth = 0.1, cmap = 'binary',\n",
    "                 yticklabels=list_fams, xticklabels=list_fams)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "print(\"Plotting the confusion matrix normalized\")\n",
    "conf_mat_norm = conf_mat/np.sum(conf_mat,axis=1)  # Normalizing the confusion matrix\n",
    "conf_mat_norm = np.around(conf_mat_norm,decimals=2)  # rounding to display in figure\n",
    "\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(20, 12)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(conf_mat_norm, cbar=False, annot=True, square=True,\n",
    "                 fmt='.2f', annot_kws={'size': 10}, linewidth = 0.1, cmap = 'binary',\n",
    "                 yticklabels=list_fams, xticklabels=list_fams)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in history:\n",
    "    print(h.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def plot_mean_acc(history):\n",
    "    train_scores = np.zeros((len(history),len(history[0].history['acc'])))\n",
    "    for fold in range(len(history)):\n",
    "        train_scores[fold] = history[fold].history['acc']\n",
    "    test_scores = np.zeros((len(history),len(history[0].history['val_acc'])))\n",
    "    for fold in range(len(history)):\n",
    "        test_scores[fold] = history[fold].history['val_acc']\n",
    "    epochs = np.linspace(0, len(history[0].history['acc']), len(history[0].history['acc']))\n",
    "    train_scores_mean = np.mean(train_scores, axis=0)\n",
    "    train_scores_std = np.std(train_scores, axis=0)\n",
    "    test_scores_mean = np.mean(test_scores, axis=0)\n",
    "    test_scores_std = np.std(test_scores, axis=0)\n",
    "    \n",
    "    figsize=(14, 6)\n",
    "    text_fontsize=\"medium\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=text_fontsize)\n",
    "    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n",
    "    ax.grid(True)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax.fill_between(epochs, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    ax.fill_between(epochs, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    ax.plot(epochs, train_scores_mean, '-', color=\"r\", linewidth=2.0, label=\"Train\")\n",
    "    ax.plot(epochs, test_scores_mean, '-', color=\"g\", linewidth=2.0, label=\"Test\")\n",
    "    ax.tick_params(labelsize=text_fontsize)\n",
    "    ax.legend(loc=\"best\", fontsize=text_fontsize)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,0.0,1.0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def plot_mean_loss(history):\n",
    "    train_scores = np.zeros((len(history),len(history[0].history['loss'])))\n",
    "    for fold in range(len(history)):\n",
    "        train_scores[fold] = history[fold].history['loss']\n",
    "    test_scores = np.zeros((len(history),len(history[0].history['val_loss'])))\n",
    "    for fold in range(len(history)):\n",
    "        test_scores[fold] = history[fold].history['val_loss']\n",
    "    epochs = np.linspace(0, len(history[0].history['loss']), len(history[0].history['loss']))\n",
    "    train_scores_mean = np.mean(train_scores, axis=0)\n",
    "    train_scores_std = np.std(train_scores, axis=0)\n",
    "    test_scores_mean = np.mean(test_scores, axis=0)\n",
    "    test_scores_std = np.std(test_scores, axis=0)\n",
    "    \n",
    "    figsize=(14, 6)\n",
    "    text_fontsize=\"medium\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=text_fontsize)\n",
    "    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n",
    "    ax.grid(True)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax.fill_between(epochs, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    ax.fill_between(epochs, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    ax.plot(epochs, train_scores_mean, '-', color=\"r\", linewidth=2.0, label=\"Train\")\n",
    "    ax.plot(epochs, test_scores_mean, '-', color=\"g\", linewidth=2.0, label=\"Test\")\n",
    "    ax.tick_params(labelsize=text_fontsize)\n",
    "    ax.legend(loc=\"best\", fontsize=text_fontsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,h in enumerate(hist):\n",
    "    print('[%d] Epoch: %d - Max val_acc: %.4f - Test acurracy: %.4f' %(i,np.argmax(h['val_acc']),np.max(h['val_acc']),h['val_acc'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def plot_mean_acc(history):\n",
    "    train_scores = np.zeros((len(history),len(history[0]['acc'])))\n",
    "    for fold in range(len(history)):\n",
    "        train_scores[fold] = history[fold]['acc']\n",
    "    test_scores = np.zeros((len(history),len(history[0]['val_acc'])))\n",
    "    for fold in range(len(history)):\n",
    "        test_scores[fold] = history[fold]['val_acc']\n",
    "    epochs = np.linspace(0, len(history[0]['acc']), len(history[0]['acc']))\n",
    "    train_scores_mean = np.mean(train_scores, axis=0)\n",
    "    train_scores_std = np.std(train_scores, axis=0)\n",
    "    test_scores_mean = np.mean(test_scores, axis=0)\n",
    "    test_scores_std = np.std(test_scores, axis=0)\n",
    "    \n",
    "    figsize=(14, 6)\n",
    "    text_fontsize=\"medium\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=text_fontsize)\n",
    "    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n",
    "    ax.grid(True)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax.fill_between(epochs, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    ax.fill_between(epochs, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    ax.plot(epochs, train_scores_mean, '-', color=\"r\", linewidth=2.0, label=\"Train\")\n",
    "    ax.plot(epochs, test_scores_mean, '-', color=\"g\", linewidth=2.0, label=\"Test\")\n",
    "    ax.tick_params(labelsize=text_fontsize)\n",
    "    ax.legend(loc=\"best\", fontsize=text_fontsize)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,0.0,1.09))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_acc(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def plot_mean_loss(history):\n",
    "    train_scores = np.zeros((len(history),len(history[0]['loss'])))\n",
    "    for fold in range(len(history)):\n",
    "        train_scores[fold] = history[fold]['loss']\n",
    "    test_scores = np.zeros((len(history),len(history[0]['val_loss'])))\n",
    "    for fold in range(len(history)):\n",
    "        test_scores[fold] = history[fold]['val_loss']\n",
    "    epochs = np.linspace(0, len(history[0]['loss']), len(history[0]['loss']))\n",
    "    train_scores_mean = np.mean(train_scores, axis=0)\n",
    "    train_scores_std = np.std(train_scores, axis=0)\n",
    "    test_scores_mean = np.mean(test_scores, axis=0)\n",
    "    test_scores_std = np.std(test_scores, axis=0)\n",
    "    \n",
    "    figsize=(14, 6)\n",
    "    text_fontsize=\"medium\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=text_fontsize)\n",
    "    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n",
    "    ax.grid(True)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax.fill_between(epochs, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    ax.fill_between(epochs, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    ax.plot(epochs, train_scores_mean, '-', color=\"r\", linewidth=2.0, label=\"Train\")\n",
    "    ax.plot(epochs, test_scores_mean, '-', color=\"g\", linewidth=2.0, alpha=0.7, label=\"Test\")\n",
    "    ax.tick_params(labelsize=text_fontsize)\n",
    "    ax.legend(loc=\"best\", fontsize=text_fontsize)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,-3.9,17.9))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_loss(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def plot_mean(history):\n",
    "    train_scores = np.zeros((len(history),len(history[0]['acc'])))\n",
    "    for fold in range(len(history)):\n",
    "        train_scores[fold] = history[fold]['acc']\n",
    "    test_scores = np.zeros((len(history),len(history[0]['val_acc'])))\n",
    "    for fold in range(len(history)):\n",
    "        test_scores[fold] = history[fold]['val_acc']\n",
    "    epochs = np.linspace(0, len(history[0]['acc']), len(history[0]['acc']))\n",
    "    train_scores_mean = np.mean(train_scores, axis=0)\n",
    "    train_scores_std = np.std(train_scores, axis=0)\n",
    "    test_scores_mean = np.mean(test_scores, axis=0)\n",
    "    test_scores_std = np.std(test_scores, axis=0)\n",
    "        \n",
    "    figsize=(14, 6)\n",
    "    text_fontsize=\"medium\"\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax1.set_xlabel(\"Epoch\", fontsize=text_fontsize)\n",
    "    ax1.set_ylabel(\"Accuracy\", fontsize=text_fontsize)\n",
    "    ax1.grid(True)\n",
    "    ax1.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "    ax1.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax1.fill_between(epochs, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    ax1.fill_between(epochs, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.1, color=\"b\")\n",
    "    ax1.plot(epochs, train_scores_mean, '-', color=\"r\", linewidth=2.0, label=\"Train acc\")\n",
    "    ax1.plot(epochs, test_scores_mean, '-', color=\"b\", linewidth=2.0, label=\"Test acc\")\n",
    "    ax1.plot(np.argmax(test_scores_mean)+1, np.max(test_scores_mean), 'o', color=\"k\", label=None)\n",
    "    ax1.annotate('Max acc: %.4f (Epoch: %d)' %(np.max(test_scores_mean),np.argmax(test_scores_mean)), xy=(np.argmax(test_scores_mean)+1, np.max(test_scores_mean)), xytext=(np.argmax(test_scores_mean)-13, np.max(test_scores_mean)-0.2), arrowprops=dict(facecolor='k', shrink=0.05),)\n",
    "    ax1.tick_params(labelsize=text_fontsize)\n",
    "    ax1.legend(loc=\"lower left\", fontsize=text_fontsize)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,0.0,1.09))\n",
    "    \n",
    "    train_scores = np.zeros((len(history),len(history[0]['loss'])))\n",
    "    for fold in range(len(history)):\n",
    "        train_scores[fold] = history[fold]['loss']\n",
    "    test_scores = np.zeros((len(history),len(history[0]['val_loss'])))\n",
    "    for fold in range(len(history)):\n",
    "        test_scores[fold] = history[fold]['val_loss']\n",
    "    epochs = np.linspace(0, len(history[0]['loss']), len(history[0]['loss']))\n",
    "    train_scores_mean = np.mean(train_scores, axis=0)\n",
    "    train_scores_std = np.std(train_scores, axis=0)\n",
    "    test_scores_mean = np.mean(test_scores, axis=0)\n",
    "    test_scores_std = np.std(test_scores, axis=0)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_xlabel(\"Epoch\", fontsize=text_fontsize)\n",
    "    ax2.set_ylabel(\"Loss\", fontsize=text_fontsize)\n",
    "    ax2.grid(False)\n",
    "    ax2.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax2.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax2.fill_between(epochs, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    ax2.fill_between(epochs, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.1, color=\"b\")\n",
    "    ax2.plot(epochs, train_scores_mean, '--', color=\"r\", linewidth=2.0, label=\"Train loss\")\n",
    "    ax2.plot(epochs, test_scores_mean, '--', color=\"b\", linewidth=2.0, label=\"Test loss\")\n",
    "    ax2.tick_params(labelsize=text_fontsize)\n",
    "    ax2.legend(loc=\"lower right\", fontsize=text_fontsize)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,-1.9,8.9))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean(hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
