{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold                                                                                                                       \n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as colormap\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,Flatten,Dense,Dropout,GlobalAveragePooling2D,Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagedir = \"Datasets/ByFamilyImagesWidth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\tFamily:         allaple\tNumber of images: 362\n",
      "Label: 1\tFamily:           alman\tNumber of images: 325\n",
      "Label: 2\tFamily:          autoit\tNumber of images: 261\n",
      "Label: 3\tFamily:            daws\tNumber of images: 466\n",
      "Label: 4\tFamily:            delf\tNumber of images: 359\n",
      "Label: 5\tFamily:         gamarue\tNumber of images: 259\n",
      "Label: 6\tFamily:          ibryte\tNumber of images: 347\n",
      "Label: 7\tFamily:          loring\tNumber of images: 285\n",
      "Label: 8\tFamily:          mydoom\tNumber of images: 578\n",
      "Label: 9\tFamily:          qukart\tNumber of images: 253\n",
      "Label:10\tFamily:          ramnit\tNumber of images: 506\n",
      "Label:11\tFamily:          sality\tNumber of images: 1401\n",
      "Label:12\tFamily:          simbot\tNumber of images: 1148\n",
      "Label:13\tFamily:       softpulse\tNumber of images: 912\n",
      "Label:14\tFamily:          viking\tNumber of images: 183\n",
      "Label:15\tFamily:         virlock\tNumber of images: 373\n",
      "Label:16\tFamily:          vobfus\tNumber of images: 405\n",
      "Label:17\tFamily:          wapomi\tNumber of images: 345\n",
      "Label:18\tFamily:            zbot\tNumber of images: 863\n",
      "Label:19\tFamily:          zegost\tNumber of images: 505\n",
      "Processing images ...\n",
      "Images processed: 10136\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(imagedir)  # the parent folder with sub-folders\n",
    "\n",
    "# Get number of samples per family\n",
    "list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names\n",
    "no_imgs = []  # No. of samples per family\n",
    "for i in range(len(list_fams)):\n",
    "    os.chdir(list_fams[i])\n",
    "    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png'\n",
    "    no_imgs.append(len1)\n",
    "    os.chdir('..')\n",
    "num_samples = np.sum(no_imgs)  # total number of all samples\n",
    "\n",
    "# Compute the labels\n",
    "y = np.zeros(num_samples)\n",
    "pos = 0\n",
    "label = 0\n",
    "for i in no_imgs:\n",
    "    print (\"Label:%2d\\tFamily: %15s\\tNumber of images: %d\" % (label, list_fams[label], i))\n",
    "    for j in range(i):\n",
    "        y[pos] = label\n",
    "        pos += 1\n",
    "    label += 1\n",
    "num_classes = label\n",
    "\n",
    "# Compute the features\n",
    "width, height,channels = (224,224,3)\n",
    "X = np.zeros((num_samples, width, height, channels))\n",
    "cnt = 0\n",
    "list_paths = [] # List of image paths\n",
    "print(\"Processing images ...\")\n",
    "for i in range(len(list_fams)):\n",
    "    for img_file in glob.glob(list_fams[i]+'/*.png'):\n",
    "        #print(\"[%d] Processing image: %s\" % (cnt, img_file))\n",
    "        list_paths.append(os.path.join(os.getcwd(),img_file))\n",
    "        img = image.load_img(img_file, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        X[cnt] = x\n",
    "        cnt += 1\n",
    "print(\"Images processed: %d\" %(cnt))\n",
    "\n",
    "os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding classes (y) into integers (y_encoded) and then generating one-hot-encoding (Y)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "Y = np_utils.to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating base_model (VGG16 convolutional layers)\n",
    "image_shape = (224, 224, 3)                                                                                                                                               \n",
    "base_model = VGG16(weights='imagenet', input_shape=image_shape, include_top=False)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VGG16 extracted features from virussign-vgg16features.npy ...\n"
     ]
    }
   ],
   "source": [
    "filename = 'virussign-vgg16features.npy'\n",
    "if os.path.exists(filename):\n",
    "    print(\"Loading VGG16 extracted features from %s ...\" %(filename))\n",
    "    vggfeatures = np.load(filename)\n",
    "else:\n",
    "    print(\"Extracting features from VGG16 convolutional layers ...\")\n",
    "    vggfeatures = base_model.predict(X)\n",
    "    print(\"Saving VGG16 extracted features into %s ...\" %(filename))\n",
    "    np.save(filename, vggfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create stratified k-fold subsets                                                                                                                                        \n",
    "kfold = 10  # no. of folds                                                                 \n",
    "skf = StratifiedKFold(kfold, shuffle=True,random_state=1)\n",
    "skfind = [None] * kfold  # skfind[i][0] -> train indices, skfind[i][1] -> test indices\n",
    "cnt = 0                                              \n",
    "for index in skf.split(X, y):         \n",
    "    skfind[cnt] = index                                                 \n",
    "    cnt += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9112 samples, validate on 1024 samples\n",
      "Epoch 1/1000\n",
      "9112/9112 [==============================] - 31s - loss: 12.8900 - acc: 0.0588 - val_loss: 6.7694 - val_acc: 0.4570\n",
      "Epoch 2/1000\n",
      "9112/9112 [==============================] - 7s - loss: 9.1721 - acc: 0.3066 - val_loss: 5.1364 - val_acc: 0.5479\n",
      "Epoch 3/1000\n",
      "9112/9112 [==============================] - 6s - loss: 7.2253 - acc: 0.4316 - val_loss: 3.8872 - val_acc: 0.6299\n",
      "Epoch 4/1000\n",
      "9112/9112 [==============================] - 6s - loss: 5.8564 - acc: 0.4915 - val_loss: 2.3118 - val_acc: 0.6797\n",
      "Epoch 5/1000\n",
      "9112/9112 [==============================] - 6s - loss: 4.4228 - acc: 0.5313 - val_loss: 1.5118 - val_acc: 0.7188\n",
      "Epoch 6/1000\n",
      "9112/9112 [==============================] - 6s - loss: 3.2894 - acc: 0.5262 - val_loss: 1.2566 - val_acc: 0.7217\n",
      "Epoch 7/1000\n",
      "9112/9112 [==============================] - 6s - loss: 2.3900 - acc: 0.5190 - val_loss: 1.3017 - val_acc: 0.6670\n",
      "Epoch 8/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.9797 - acc: 0.5033 - val_loss: 1.3884 - val_acc: 0.6416\n",
      "Epoch 9/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.8095 - acc: 0.5008 - val_loss: 1.3897 - val_acc: 0.6416\n",
      "Epoch 10/1000\n",
      "9112/9112 [==============================] - 7s - loss: 1.7704 - acc: 0.5003 - val_loss: 1.3482 - val_acc: 0.6523\n",
      "Epoch 11/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.7395 - acc: 0.5125 - val_loss: 1.2788 - val_acc: 0.7305\n",
      "Epoch 12/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.6793 - acc: 0.5294 - val_loss: 1.2013 - val_acc: 0.7305\n",
      "Epoch 13/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.6179 - acc: 0.5656 - val_loss: 1.1598 - val_acc: 0.7490\n",
      "Epoch 14/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.5556 - acc: 0.5797 - val_loss: 1.1092 - val_acc: 0.7617\n",
      "Epoch 15/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.5094 - acc: 0.5944 - val_loss: 1.0718 - val_acc: 0.7705\n",
      "Epoch 16/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.4537 - acc: 0.6091 - val_loss: 1.0372 - val_acc: 0.7744\n",
      "Epoch 17/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.4471 - acc: 0.6144 - val_loss: 1.0112 - val_acc: 0.7793\n",
      "Epoch 18/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.3999 - acc: 0.6304 - val_loss: 0.9900 - val_acc: 0.7822\n",
      "Epoch 19/1000\n",
      "9112/9112 [==============================] - 7s - loss: 1.3653 - acc: 0.6319 - val_loss: 0.9651 - val_acc: 0.7861\n",
      "Epoch 20/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.2973 - acc: 0.6536 - val_loss: 0.9355 - val_acc: 0.7891\n",
      "Epoch 21/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.2811 - acc: 0.6591 - val_loss: 0.9062 - val_acc: 0.7900\n",
      "Epoch 22/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.2651 - acc: 0.6636 - val_loss: 0.8873 - val_acc: 0.7939\n",
      "Epoch 23/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.2100 - acc: 0.6757 - val_loss: 0.8726 - val_acc: 0.7949\n",
      "Epoch 24/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.2067 - acc: 0.6799 - val_loss: 0.8566 - val_acc: 0.7979\n",
      "Epoch 25/1000\n",
      "9112/9112 [==============================] - 7s - loss: 1.1648 - acc: 0.6839 - val_loss: 0.8387 - val_acc: 0.8076\n",
      "Epoch 26/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.1352 - acc: 0.6903 - val_loss: 0.8231 - val_acc: 0.8096\n",
      "Epoch 27/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.1038 - acc: 0.6978 - val_loss: 0.8084 - val_acc: 0.8232\n",
      "Epoch 28/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.0828 - acc: 0.7077 - val_loss: 0.7778 - val_acc: 0.8281\n",
      "Epoch 29/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.0548 - acc: 0.7151 - val_loss: 0.7471 - val_acc: 0.8262\n",
      "Epoch 30/1000\n",
      "9112/9112 [==============================] - 6s - loss: 1.0601 - acc: 0.7176 - val_loss: 0.7363 - val_acc: 0.8340\n",
      "Epoch 31/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.9989 - acc: 0.7260 - val_loss: 0.7252 - val_acc: 0.8330\n",
      "Epoch 32/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.9791 - acc: 0.7333 - val_loss: 0.7071 - val_acc: 0.8359\n",
      "Epoch 33/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.9738 - acc: 0.7313 - val_loss: 0.6889 - val_acc: 0.8408\n",
      "Epoch 34/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.9503 - acc: 0.7338 - val_loss: 0.6684 - val_acc: 0.8408\n",
      "Epoch 35/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.9251 - acc: 0.7400 - val_loss: 0.6550 - val_acc: 0.8398\n",
      "Epoch 36/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.9145 - acc: 0.7420 - val_loss: 0.6564 - val_acc: 0.8428\n",
      "Epoch 37/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.9162 - acc: 0.7459 - val_loss: 0.6647 - val_acc: 0.8398\n",
      "Epoch 38/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8786 - acc: 0.7547 - val_loss: 0.6642 - val_acc: 0.8408\n",
      "Epoch 39/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8821 - acc: 0.7486 - val_loss: 0.6595 - val_acc: 0.8428\n",
      "Epoch 40/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8685 - acc: 0.7545 - val_loss: 0.6605 - val_acc: 0.8428\n",
      "Epoch 41/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8525 - acc: 0.7572 - val_loss: 0.6611 - val_acc: 0.8418\n",
      "Epoch 42/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8469 - acc: 0.7575 - val_loss: 0.6602 - val_acc: 0.8408\n",
      "Epoch 43/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8441 - acc: 0.7579 - val_loss: 0.6578 - val_acc: 0.8438\n",
      "Epoch 44/1000\n",
      "9112/9112 [==============================] - 7s - loss: 0.8370 - acc: 0.7619 - val_loss: 0.6581 - val_acc: 0.8447\n",
      "Epoch 45/1000\n",
      "9112/9112 [==============================] - 7s - loss: 0.8259 - acc: 0.7611 - val_loss: 0.6657 - val_acc: 0.8447\n",
      "Epoch 46/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8228 - acc: 0.7624 - val_loss: 0.6658 - val_acc: 0.8428\n",
      "Epoch 47/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7995 - acc: 0.7669 - val_loss: 0.6499 - val_acc: 0.8447\n",
      "Epoch 48/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8154 - acc: 0.7615 - val_loss: 0.6379 - val_acc: 0.8447\n",
      "Epoch 49/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.8004 - acc: 0.7668 - val_loss: 0.6341 - val_acc: 0.8438\n",
      "Epoch 50/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7960 - acc: 0.7713 - val_loss: 0.6399 - val_acc: 0.8428\n",
      "Epoch 51/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7871 - acc: 0.7687 - val_loss: 0.6412 - val_acc: 0.8457\n",
      "Epoch 52/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7841 - acc: 0.7666 - val_loss: 0.6364 - val_acc: 0.8438\n",
      "Epoch 53/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7877 - acc: 0.7684 - val_loss: 0.6266 - val_acc: 0.8457\n",
      "Epoch 54/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7836 - acc: 0.7682 - val_loss: 0.6150 - val_acc: 0.8447\n",
      "Epoch 55/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.7783 - acc: 0.7729 - val_loss: 0.6128 - val_acc: 0.8457\n",
      "Epoch 56/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7717 - acc: 0.7709 - val_loss: 0.6241 - val_acc: 0.8447\n",
      "Epoch 57/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7700 - acc: 0.7726 - val_loss: 0.6333 - val_acc: 0.8447\n",
      "Epoch 58/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7541 - acc: 0.7758 - val_loss: 0.6219 - val_acc: 0.8438\n",
      "Epoch 59/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7506 - acc: 0.7767 - val_loss: 0.6149 - val_acc: 0.8457\n",
      "Epoch 60/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7416 - acc: 0.7774 - val_loss: 0.6171 - val_acc: 0.8486\n",
      "Epoch 61/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7364 - acc: 0.7803 - val_loss: 0.6268 - val_acc: 0.8438\n",
      "Epoch 62/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.7280 - acc: 0.7815 - val_loss: 0.6344 - val_acc: 0.8447\n",
      "Epoch 63/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.7222 - acc: 0.7853 - val_loss: 0.6252 - val_acc: 0.8477\n",
      "Epoch 64/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9112/9112 [==============================] - 6s - loss: 0.7083 - acc: 0.7906 - val_loss: 0.6105 - val_acc: 0.8477\n",
      "Epoch 65/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6971 - acc: 0.7916 - val_loss: 0.6129 - val_acc: 0.8477\n",
      "Epoch 66/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6832 - acc: 0.7984 - val_loss: 0.6257 - val_acc: 0.8477\n",
      "Epoch 67/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6811 - acc: 0.7987 - val_loss: 0.6260 - val_acc: 0.8486\n",
      "Epoch 68/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6704 - acc: 0.7976 - val_loss: 0.6245 - val_acc: 0.8496\n",
      "Epoch 69/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.6743 - acc: 0.7993 - val_loss: 0.6174 - val_acc: 0.8496\n",
      "Epoch 70/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6803 - acc: 0.7964 - val_loss: 0.6098 - val_acc: 0.8506\n",
      "Epoch 71/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6682 - acc: 0.7992 - val_loss: 0.6156 - val_acc: 0.8496\n",
      "Epoch 72/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6509 - acc: 0.8054 - val_loss: 0.6194 - val_acc: 0.8506\n",
      "Epoch 73/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6502 - acc: 0.8020 - val_loss: 0.6299 - val_acc: 0.8525\n",
      "Epoch 74/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.6603 - acc: 0.8008 - val_loss: 0.6336 - val_acc: 0.8496\n",
      "Epoch 75/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6554 - acc: 0.8031 - val_loss: 0.6338 - val_acc: 0.8496\n",
      "Epoch 76/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6420 - acc: 0.8015 - val_loss: 0.6397 - val_acc: 0.8496\n",
      "Epoch 77/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6325 - acc: 0.8081 - val_loss: 0.6492 - val_acc: 0.8477\n",
      "Epoch 78/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6488 - acc: 0.8022 - val_loss: 0.6348 - val_acc: 0.8486\n",
      "Epoch 79/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6458 - acc: 0.8038 - val_loss: 0.6242 - val_acc: 0.8486\n",
      "Epoch 80/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6463 - acc: 0.8040 - val_loss: 0.6230 - val_acc: 0.8525\n",
      "Epoch 81/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.6384 - acc: 0.8073 - val_loss: 0.6304 - val_acc: 0.8545\n",
      "Epoch 82/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6422 - acc: 0.8053 - val_loss: 0.6320 - val_acc: 0.8516\n",
      "Epoch 83/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6361 - acc: 0.8020 - val_loss: 0.6247 - val_acc: 0.8525\n",
      "Epoch 84/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6201 - acc: 0.8066 - val_loss: 0.6209 - val_acc: 0.8496\n",
      "Epoch 85/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.6200 - acc: 0.8086 - val_loss: 0.6231 - val_acc: 0.8496\n",
      "Epoch 86/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6276 - acc: 0.8079 - val_loss: 0.6282 - val_acc: 0.8525\n",
      "Epoch 87/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6294 - acc: 0.8071 - val_loss: 0.6347 - val_acc: 0.8516\n",
      "Epoch 88/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6149 - acc: 0.8103 - val_loss: 0.6366 - val_acc: 0.8506\n",
      "Epoch 89/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6161 - acc: 0.8090 - val_loss: 0.6447 - val_acc: 0.8506\n",
      "Epoch 90/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6277 - acc: 0.8086 - val_loss: 0.6442 - val_acc: 0.8525\n",
      "Epoch 91/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6273 - acc: 0.8068 - val_loss: 0.6385 - val_acc: 0.8506\n",
      "Epoch 92/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6239 - acc: 0.8082 - val_loss: 0.6322 - val_acc: 0.8535\n",
      "Epoch 93/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6072 - acc: 0.8113 - val_loss: 0.6272 - val_acc: 0.8545\n",
      "Epoch 94/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6007 - acc: 0.8151 - val_loss: 0.6266 - val_acc: 0.8516\n",
      "Epoch 95/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6031 - acc: 0.8134 - val_loss: 0.6370 - val_acc: 0.8535\n",
      "Epoch 96/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6073 - acc: 0.8137 - val_loss: 0.6515 - val_acc: 0.8564\n",
      "Epoch 97/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6048 - acc: 0.8095 - val_loss: 0.6668 - val_acc: 0.8564\n",
      "Epoch 98/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6097 - acc: 0.8116 - val_loss: 0.6506 - val_acc: 0.8574\n",
      "Epoch 99/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5880 - acc: 0.8188 - val_loss: 0.6434 - val_acc: 0.8535\n",
      "Epoch 100/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5931 - acc: 0.8152 - val_loss: 0.6473 - val_acc: 0.8525\n",
      "Epoch 101/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5930 - acc: 0.8173 - val_loss: 0.6503 - val_acc: 0.8564\n",
      "Epoch 102/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5817 - acc: 0.8175 - val_loss: 0.6671 - val_acc: 0.8584\n",
      "Epoch 103/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5903 - acc: 0.8157 - val_loss: 0.6505 - val_acc: 0.8555\n",
      "Epoch 104/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5948 - acc: 0.8131 - val_loss: 0.6264 - val_acc: 0.8545\n",
      "Epoch 105/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5912 - acc: 0.8164 - val_loss: 0.6203 - val_acc: 0.8555\n",
      "Epoch 106/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.6033 - acc: 0.8111 - val_loss: 0.6207 - val_acc: 0.8584\n",
      "Epoch 107/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5772 - acc: 0.8169 - val_loss: 0.6276 - val_acc: 0.8594\n",
      "Epoch 108/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5772 - acc: 0.8185 - val_loss: 0.6232 - val_acc: 0.8594\n",
      "Epoch 109/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5900 - acc: 0.8106 - val_loss: 0.6162 - val_acc: 0.8584\n",
      "Epoch 110/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5772 - acc: 0.8199 - val_loss: 0.6168 - val_acc: 0.8564\n",
      "Epoch 111/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5670 - acc: 0.8211 - val_loss: 0.6248 - val_acc: 0.8574\n",
      "Epoch 112/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5633 - acc: 0.8233 - val_loss: 0.6324 - val_acc: 0.8574\n",
      "Epoch 113/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5639 - acc: 0.8231 - val_loss: 0.6400 - val_acc: 0.8594\n",
      "Epoch 114/1000\n",
      "9112/9112 [==============================] - 7s - loss: 0.5790 - acc: 0.8158 - val_loss: 0.6330 - val_acc: 0.8613\n",
      "Epoch 115/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5675 - acc: 0.8197 - val_loss: 0.6292 - val_acc: 0.8594\n",
      "Epoch 116/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5833 - acc: 0.8188 - val_loss: 0.6332 - val_acc: 0.8574\n",
      "Epoch 117/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5638 - acc: 0.8212 - val_loss: 0.6157 - val_acc: 0.8604\n",
      "Epoch 118/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5569 - acc: 0.8236 - val_loss: 0.6067 - val_acc: 0.8594\n",
      "Epoch 119/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5805 - acc: 0.8186 - val_loss: 0.6048 - val_acc: 0.8604\n",
      "Epoch 120/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5595 - acc: 0.8223 - val_loss: 0.6029 - val_acc: 0.8613\n",
      "Epoch 121/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5559 - acc: 0.8241 - val_loss: 0.6098 - val_acc: 0.8623\n",
      "Epoch 122/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5614 - acc: 0.8194 - val_loss: 0.6138 - val_acc: 0.8643\n",
      "Epoch 123/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5533 - acc: 0.8230 - val_loss: 0.6222 - val_acc: 0.8623\n",
      "Epoch 124/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5612 - acc: 0.8190 - val_loss: 0.6198 - val_acc: 0.8623\n",
      "Epoch 125/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5471 - acc: 0.8247 - val_loss: 0.6112 - val_acc: 0.8623\n",
      "Epoch 126/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5426 - acc: 0.8264 - val_loss: 0.6060 - val_acc: 0.8604\n",
      "Epoch 127/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9112/9112 [==============================] - 6s - loss: 0.5593 - acc: 0.8232 - val_loss: 0.5987 - val_acc: 0.8623\n",
      "Epoch 128/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5533 - acc: 0.8231 - val_loss: 0.5985 - val_acc: 0.8652\n",
      "Epoch 129/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5532 - acc: 0.8201 - val_loss: 0.6057 - val_acc: 0.8682\n",
      "Epoch 130/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5498 - acc: 0.8228 - val_loss: 0.6053 - val_acc: 0.8682\n",
      "Epoch 131/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5383 - acc: 0.8295 - val_loss: 0.6175 - val_acc: 0.8623\n",
      "Epoch 132/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5365 - acc: 0.8251 - val_loss: 0.6237 - val_acc: 0.8643\n",
      "Epoch 133/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5467 - acc: 0.8231 - val_loss: 0.6108 - val_acc: 0.8682\n",
      "Epoch 134/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5453 - acc: 0.8231 - val_loss: 0.6054 - val_acc: 0.8652\n",
      "Epoch 135/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5512 - acc: 0.8243 - val_loss: 0.6001 - val_acc: 0.8623\n",
      "Epoch 136/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5498 - acc: 0.8244 - val_loss: 0.6039 - val_acc: 0.8613\n",
      "Epoch 137/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5366 - acc: 0.8272 - val_loss: 0.6128 - val_acc: 0.8613\n",
      "Epoch 138/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5237 - acc: 0.8292 - val_loss: 0.6164 - val_acc: 0.8633\n",
      "Epoch 139/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5453 - acc: 0.8228 - val_loss: 0.6112 - val_acc: 0.8633\n",
      "Epoch 140/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5350 - acc: 0.8295 - val_loss: 0.6079 - val_acc: 0.8623\n",
      "Epoch 141/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5522 - acc: 0.8217 - val_loss: 0.6019 - val_acc: 0.8564\n",
      "Epoch 142/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5390 - acc: 0.8251 - val_loss: 0.6001 - val_acc: 0.8594\n",
      "Epoch 143/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5427 - acc: 0.8263 - val_loss: 0.6118 - val_acc: 0.8594\n",
      "Epoch 144/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5379 - acc: 0.8265 - val_loss: 0.6143 - val_acc: 0.8613\n",
      "Epoch 145/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5291 - acc: 0.8317 - val_loss: 0.6191 - val_acc: 0.8594\n",
      "Epoch 146/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5217 - acc: 0.8297 - val_loss: 0.6160 - val_acc: 0.8584\n",
      "Epoch 147/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5388 - acc: 0.8242 - val_loss: 0.6204 - val_acc: 0.8604\n",
      "Epoch 148/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5209 - acc: 0.8273 - val_loss: 0.6264 - val_acc: 0.8623\n",
      "Epoch 149/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5363 - acc: 0.8280 - val_loss: 0.6226 - val_acc: 0.8623\n",
      "Epoch 150/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5326 - acc: 0.8250 - val_loss: 0.6183 - val_acc: 0.8594\n",
      "Epoch 151/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5316 - acc: 0.8258 - val_loss: 0.6032 - val_acc: 0.8623\n",
      "Epoch 152/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5379 - acc: 0.8248 - val_loss: 0.6037 - val_acc: 0.8604\n",
      "Epoch 153/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5291 - acc: 0.8256 - val_loss: 0.6165 - val_acc: 0.8633\n",
      "Epoch 154/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5325 - acc: 0.8286 - val_loss: 0.6228 - val_acc: 0.8662\n",
      "Epoch 155/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5291 - acc: 0.8279 - val_loss: 0.6201 - val_acc: 0.8662\n",
      "Epoch 156/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5353 - acc: 0.8251 - val_loss: 0.6232 - val_acc: 0.8633\n",
      "Epoch 157/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5306 - acc: 0.8265 - val_loss: 0.6209 - val_acc: 0.8662\n",
      "Epoch 158/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5185 - acc: 0.8287 - val_loss: 0.6245 - val_acc: 0.8652\n",
      "Epoch 159/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5148 - acc: 0.8334 - val_loss: 0.6306 - val_acc: 0.8652\n",
      "Epoch 160/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5205 - acc: 0.8306 - val_loss: 0.6293 - val_acc: 0.8662\n",
      "Epoch 161/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5340 - acc: 0.8261 - val_loss: 0.6284 - val_acc: 0.8672\n",
      "Epoch 162/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5262 - acc: 0.8284 - val_loss: 0.6166 - val_acc: 0.8662\n",
      "Epoch 163/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5139 - acc: 0.8293 - val_loss: 0.6100 - val_acc: 0.8652\n",
      "Epoch 164/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5147 - acc: 0.8313 - val_loss: 0.6069 - val_acc: 0.8643\n",
      "Epoch 165/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5264 - acc: 0.8290 - val_loss: 0.6111 - val_acc: 0.8613\n",
      "Epoch 166/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5107 - acc: 0.8346 - val_loss: 0.6203 - val_acc: 0.8643\n",
      "Epoch 167/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5209 - acc: 0.8302 - val_loss: 0.6191 - val_acc: 0.8652\n",
      "Epoch 168/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5230 - acc: 0.8298 - val_loss: 0.6053 - val_acc: 0.8633\n",
      "Epoch 169/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5235 - acc: 0.8290 - val_loss: 0.6082 - val_acc: 0.8633\n",
      "Epoch 170/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5130 - acc: 0.8291 - val_loss: 0.6078 - val_acc: 0.8652\n",
      "Epoch 171/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5104 - acc: 0.8331 - val_loss: 0.6165 - val_acc: 0.8643\n",
      "Epoch 172/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5136 - acc: 0.8319 - val_loss: 0.6223 - val_acc: 0.8662\n",
      "Epoch 173/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5266 - acc: 0.8261 - val_loss: 0.6204 - val_acc: 0.8682\n",
      "Epoch 174/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5201 - acc: 0.8295 - val_loss: 0.6190 - val_acc: 0.8662\n",
      "Epoch 175/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5301 - acc: 0.8282 - val_loss: 0.6323 - val_acc: 0.8652\n",
      "Epoch 176/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5074 - acc: 0.8369 - val_loss: 0.6458 - val_acc: 0.8643\n",
      "Epoch 177/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5219 - acc: 0.8325 - val_loss: 0.6335 - val_acc: 0.8672\n",
      "Epoch 178/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4958 - acc: 0.8379 - val_loss: 0.6294 - val_acc: 0.8672\n",
      "Epoch 179/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5159 - acc: 0.8310 - val_loss: 0.6328 - val_acc: 0.8672\n",
      "Epoch 180/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5091 - acc: 0.8357 - val_loss: 0.6311 - val_acc: 0.8652\n",
      "Epoch 181/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5126 - acc: 0.8318 - val_loss: 0.6170 - val_acc: 0.8691\n",
      "Epoch 182/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5082 - acc: 0.8335 - val_loss: 0.6163 - val_acc: 0.8691\n",
      "Epoch 183/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5229 - acc: 0.8276 - val_loss: 0.6281 - val_acc: 0.8701\n",
      "Epoch 184/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5239 - acc: 0.8298 - val_loss: 0.6429 - val_acc: 0.8672\n",
      "Epoch 185/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5008 - acc: 0.8338 - val_loss: 0.6414 - val_acc: 0.8643\n",
      "Epoch 186/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5119 - acc: 0.8323 - val_loss: 0.6373 - val_acc: 0.8613\n",
      "Epoch 187/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5059 - acc: 0.8352 - val_loss: 0.6364 - val_acc: 0.8594\n",
      "Epoch 188/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5102 - acc: 0.8313 - val_loss: 0.6380 - val_acc: 0.8613\n",
      "Epoch 189/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.5161 - acc: 0.8307 - val_loss: 0.6445 - val_acc: 0.8643\n",
      "Epoch 190/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9112/9112 [==============================] - 5s - loss: 0.5061 - acc: 0.8330 - val_loss: 0.6522 - val_acc: 0.8643\n",
      "Epoch 191/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5170 - acc: 0.8321 - val_loss: 0.6443 - val_acc: 0.8662\n",
      "Epoch 192/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4995 - acc: 0.8359 - val_loss: 0.6339 - val_acc: 0.8662\n",
      "Epoch 193/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4924 - acc: 0.8386 - val_loss: 0.6307 - val_acc: 0.8662\n",
      "Epoch 194/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5131 - acc: 0.8333 - val_loss: 0.6384 - val_acc: 0.8691\n",
      "Epoch 195/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4978 - acc: 0.8357 - val_loss: 0.6445 - val_acc: 0.8652\n",
      "Epoch 196/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5045 - acc: 0.8346 - val_loss: 0.6260 - val_acc: 0.8682\n",
      "Epoch 197/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5113 - acc: 0.8311 - val_loss: 0.6147 - val_acc: 0.8672\n",
      "Epoch 198/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4898 - acc: 0.8387 - val_loss: 0.6111 - val_acc: 0.8682\n",
      "Epoch 199/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4918 - acc: 0.8382 - val_loss: 0.6114 - val_acc: 0.8691\n",
      "Epoch 200/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4918 - acc: 0.8355 - val_loss: 0.6111 - val_acc: 0.8682\n",
      "Epoch 201/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5005 - acc: 0.8376 - val_loss: 0.6068 - val_acc: 0.8662\n",
      "Epoch 202/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.5009 - acc: 0.8372 - val_loss: 0.6018 - val_acc: 0.8672\n",
      "Epoch 203/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4912 - acc: 0.8423 - val_loss: 0.6148 - val_acc: 0.8623\n",
      "Epoch 204/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4944 - acc: 0.8381 - val_loss: 0.6247 - val_acc: 0.8662\n",
      "Epoch 205/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4807 - acc: 0.8423 - val_loss: 0.6233 - val_acc: 0.8682\n",
      "Epoch 206/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4901 - acc: 0.8405 - val_loss: 0.6097 - val_acc: 0.8662\n",
      "Epoch 207/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4917 - acc: 0.8417 - val_loss: 0.6064 - val_acc: 0.8652\n",
      "Epoch 208/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4910 - acc: 0.8424 - val_loss: 0.6124 - val_acc: 0.8643\n",
      "Epoch 209/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4886 - acc: 0.8417 - val_loss: 0.6196 - val_acc: 0.8633\n",
      "Epoch 210/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4883 - acc: 0.8419 - val_loss: 0.6222 - val_acc: 0.8633\n",
      "Epoch 211/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4835 - acc: 0.8432 - val_loss: 0.6199 - val_acc: 0.8613\n",
      "Epoch 212/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4852 - acc: 0.8383 - val_loss: 0.6078 - val_acc: 0.8662\n",
      "Epoch 213/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4799 - acc: 0.8443 - val_loss: 0.6060 - val_acc: 0.8633\n",
      "Epoch 214/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4843 - acc: 0.8423 - val_loss: 0.6167 - val_acc: 0.8633\n",
      "Epoch 215/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4883 - acc: 0.8430 - val_loss: 0.6026 - val_acc: 0.8662\n",
      "Epoch 216/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4874 - acc: 0.8424 - val_loss: 0.5885 - val_acc: 0.8662\n",
      "Epoch 217/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4796 - acc: 0.8462 - val_loss: 0.5872 - val_acc: 0.8662\n",
      "Epoch 218/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4993 - acc: 0.8387 - val_loss: 0.6007 - val_acc: 0.8643\n",
      "Epoch 219/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4854 - acc: 0.8399 - val_loss: 0.5943 - val_acc: 0.8672\n",
      "Epoch 220/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4834 - acc: 0.8398 - val_loss: 0.6014 - val_acc: 0.8672\n",
      "Epoch 221/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4838 - acc: 0.8424 - val_loss: 0.6112 - val_acc: 0.8672\n",
      "Epoch 222/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4819 - acc: 0.8430 - val_loss: 0.6159 - val_acc: 0.8711\n",
      "Epoch 223/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4802 - acc: 0.8438 - val_loss: 0.6106 - val_acc: 0.8691\n",
      "Epoch 224/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4748 - acc: 0.8428 - val_loss: 0.5933 - val_acc: 0.8721\n",
      "Epoch 225/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4824 - acc: 0.8424 - val_loss: 0.5814 - val_acc: 0.8730\n",
      "Epoch 226/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4819 - acc: 0.8427 - val_loss: 0.5873 - val_acc: 0.8721\n",
      "Epoch 227/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4910 - acc: 0.8380 - val_loss: 0.6007 - val_acc: 0.8691\n",
      "Epoch 228/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4865 - acc: 0.8426 - val_loss: 0.5916 - val_acc: 0.8691\n",
      "Epoch 229/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4814 - acc: 0.8445 - val_loss: 0.5849 - val_acc: 0.8740\n",
      "Epoch 230/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4802 - acc: 0.8423 - val_loss: 0.5883 - val_acc: 0.8730\n",
      "Epoch 231/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4768 - acc: 0.8450 - val_loss: 0.5974 - val_acc: 0.8750\n",
      "Epoch 232/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4794 - acc: 0.8432 - val_loss: 0.6007 - val_acc: 0.8740\n",
      "Epoch 233/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4687 - acc: 0.8479 - val_loss: 0.5910 - val_acc: 0.8740\n",
      "Epoch 234/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4790 - acc: 0.8453 - val_loss: 0.5890 - val_acc: 0.8740\n",
      "Epoch 235/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4780 - acc: 0.8438 - val_loss: 0.5902 - val_acc: 0.8740\n",
      "Epoch 236/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4650 - acc: 0.8472 - val_loss: 0.6001 - val_acc: 0.8711\n",
      "Epoch 237/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4795 - acc: 0.8412 - val_loss: 0.6086 - val_acc: 0.8721\n",
      "Epoch 238/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4762 - acc: 0.8457 - val_loss: 0.6049 - val_acc: 0.8730\n",
      "Epoch 239/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4791 - acc: 0.8455 - val_loss: 0.5980 - val_acc: 0.8750\n",
      "Epoch 240/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4736 - acc: 0.8439 - val_loss: 0.5998 - val_acc: 0.8809\n",
      "Epoch 241/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4628 - acc: 0.8478 - val_loss: 0.6043 - val_acc: 0.8789\n",
      "Epoch 242/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4681 - acc: 0.8478 - val_loss: 0.6065 - val_acc: 0.8770\n",
      "Epoch 243/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4649 - acc: 0.8499 - val_loss: 0.6081 - val_acc: 0.8828\n",
      "Epoch 244/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4751 - acc: 0.8456 - val_loss: 0.5990 - val_acc: 0.8848\n",
      "Epoch 245/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4728 - acc: 0.8479 - val_loss: 0.5983 - val_acc: 0.8779\n",
      "Epoch 246/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4682 - acc: 0.8475 - val_loss: 0.6085 - val_acc: 0.8779\n",
      "Epoch 247/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4614 - acc: 0.8499 - val_loss: 0.5969 - val_acc: 0.8799\n",
      "Epoch 248/1000\n",
      "9112/9112 [==============================] - 5s - loss: 0.4817 - acc: 0.8424 - val_loss: 0.5844 - val_acc: 0.8828\n",
      "Epoch 249/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4778 - acc: 0.8444 - val_loss: 0.5840 - val_acc: 0.8789\n",
      "Epoch 250/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4736 - acc: 0.8482 - val_loss: 0.5828 - val_acc: 0.8779\n",
      "Epoch 251/1000\n",
      "9112/9112 [==============================] - 6s - loss: 0.4575 - acc: 0.8557 - val_loss: 0.5785 - val_acc: 0.8828\n",
      "Epoch 252/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-28781e5bb69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtop_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training top_model and saving min training loss weights\n",
    "num_epochs=1000\n",
    "history = []\n",
    "conf_mat = np.zeros((len(list_fams),len(list_fams))) # Initializing the Confusion Matrix\n",
    "checkpointer = ModelCheckpoint(filepath='model-min_loss-vgg16-2layers-160neurons-relu-0.4dropout-Adam-1000epochs.h5', monitor='loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "for i in range(kfold):\n",
    "    train_indices = skfind[i][0]\n",
    "    test_indices = skfind[i][1]\n",
    "    X_train = vggfeatures[train_indices]\n",
    "    Y_train = Y[train_indices]\n",
    "    X_test = vggfeatures[test_indices]\n",
    "    Y_test = Y[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    top_model = Sequential() \n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:])) # input_shape=(7,7,512)                                                \n",
    "    top_model.add(Dense(160, activation='relu', name='fc1'))\n",
    "    top_model.add(Dropout(0.4))                \n",
    "    top_model.add(Dense(160, activation='relu', name='fc2'))\n",
    "    top_model.add(Dropout(0.4))              \n",
    "    top_model.add(Dense(num_classes, activation='softmax', name='predictions'))                             \n",
    "    top_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    h = top_model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=num_epochs, batch_size=X_train.shape[0], verbose=1, callbacks=[checkpointer])\n",
    "    history.append(h)\n",
    "    \n",
    "    y_prob = top_model.predict(X_test, verbose=0)  # Testing\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    print(\"[%d] Test acurracy: %.4f\" %(i,accuracy_score(y_test,y_pred)))\n",
    "    cm = confusion_matrix(y_test,y_pred)  # Compute confusion matrix for this fold\n",
    "    conf_mat = conf_mat + cm  # Compute global confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the average accuracy\n",
    "avg_acc = np.trace(conf_mat)/np.sum(conf_mat)\n",
    "print(\"Average acurracy: %.4f\" %(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_acc(history):\n",
    "    figure = plt.gcf()\n",
    "    figure.set_size_inches(24, 9)\n",
    "    ax = plt.subplot()\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    colors = iter(colormap.gist_rainbow(np.linspace(0, 1, len(history))))\n",
    "    for i in range(len(history)):\n",
    "        color=next(colors)\n",
    "        plt.plot(history[i].history['acc'], label='Train '+str(i), color=color, linestyle = 'solid')\n",
    "        plt.plot(history[i].history['val_acc'], label='Test '+str(i), color=color, linestyle = 'dotted')\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,0.0,1.0))\n",
    "    plt.legend()\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    figure = plt.gcf()\n",
    "    figure.set_size_inches(24, 9)\n",
    "    ax = plt.subplot()\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    colors = iter(colormap.gist_rainbow(np.linspace(0, 1, len(history))))\n",
    "    for i in range(len(history)):\n",
    "        color=next(colors)\n",
    "        plt.plot(history[i].history['loss'], label='Train '+str(i), color=color, linestyle = 'solid')\n",
    "        plt.plot(history[i].history['val_loss'], label='Test '+str(i), color=color, linestyle = 'dotted')\n",
    "    plt.legend()\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Plotting the confusion matrix\")\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(18, 12)\n",
    "plt.imshow(conf_mat,interpolation='nearest',cmap='coolwarm')\n",
    "for row in range(len(list_fams)):\n",
    "    for col in range(len(list_fams)):\n",
    "        plt.annotate(str(int(conf_mat[row][col])),xy=(col,row),ha='center',va='center')\n",
    "plt.xticks(range(len(list_fams)),list_fams,rotation=90,fontsize=10)\n",
    "plt.yticks(range(len(list_fams)),list_fams,fontsize=10)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Plotting the confusion matrix normalized\")\n",
    "conf_mat_norm = conf_mat/np.sum(conf_mat,axis=1)  # Normalizing the confusion matrix\n",
    "conf_mat_norm = np.around(conf_mat_norm,decimals=2)  # rounding to display in figure\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(20, 12)\n",
    "plt.imshow(conf_mat_norm,interpolation='nearest',cmap='seismic')\n",
    "for row in range(len(list_fams)):\n",
    "    for col in range(len(list_fams)):\n",
    "        plt.annotate(str(conf_mat_norm[row][col]),xy=(col,row),ha='center',va='center')\n",
    "plt.xticks(range(len(list_fams)),list_fams,rotation=90,fontsize=10)\n",
    "plt.yticks(range(len(list_fams)),list_fams,fontsize=10)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Plotting the confusion matrix normalized\")\n",
    "conf_mat_norm = conf_mat/np.sum(conf_mat,axis=1)  # Normalizing the confusion matrix\n",
    "conf_mat_norm = np.around(conf_mat_norm,decimals=2)  # rounding to display in figure\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(20, 12)\n",
    "plt.imshow(conf_mat_norm,interpolation='nearest',cmap='binary')\n",
    "#for row in range(len(list_fams)):\n",
    "#    for col in range(len(list_fams)):\n",
    "#        plt.annotate(str(conf_mat_norm[row][col]),xy=(col,row),ha='center',va='center')\n",
    "plt.xticks(range(len(list_fams)),list_fams,rotation=90,fontsize=10)\n",
    "plt.yticks(range(len(list_fams)),list_fams,fontsize=10)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
