{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as colormap\n",
    "import time\n",
    "\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold                              \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,Flatten,Dense,Dropout,GlobalAveragePooling2D,Conv2D,MaxPooling2D\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "from vis.utils import utils\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from vis.visualization import visualize_cam,visualize_saliency,overlay\n",
    "from keras import activations\n",
    "\n",
    "# Disable GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagedir = \"Datasets/ByFamilyImagesWidth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\tFamily:         allaple\tNumber of images: 362\n",
      "Label: 1\tFamily:           alman\tNumber of images: 325\n",
      "Label: 2\tFamily:          autoit\tNumber of images: 261\n",
      "Label: 3\tFamily:            daws\tNumber of images: 466\n",
      "Label: 4\tFamily:            delf\tNumber of images: 359\n",
      "Label: 5\tFamily:         gamarue\tNumber of images: 259\n",
      "Label: 6\tFamily:          ibryte\tNumber of images: 347\n",
      "Label: 7\tFamily:          loring\tNumber of images: 285\n",
      "Label: 8\tFamily:          mydoom\tNumber of images: 578\n",
      "Label: 9\tFamily:          qukart\tNumber of images: 253\n",
      "Label:10\tFamily:          ramnit\tNumber of images: 506\n",
      "Label:11\tFamily:          sality\tNumber of images: 1401\n",
      "Label:12\tFamily:          simbot\tNumber of images: 1148\n",
      "Label:13\tFamily:       softpulse\tNumber of images: 912\n",
      "Label:14\tFamily:          viking\tNumber of images: 183\n",
      "Label:15\tFamily:         virlock\tNumber of images: 373\n",
      "Label:16\tFamily:          vobfus\tNumber of images: 405\n",
      "Label:17\tFamily:          wapomi\tNumber of images: 345\n",
      "Label:18\tFamily:            zbot\tNumber of images: 863\n",
      "Label:19\tFamily:          zegost\tNumber of images: 505\n",
      "Processing images ...\n",
      "Images processed: 10136\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(imagedir)  # the parent folder with sub-folders\n",
    "\n",
    "# Get number of samples per family\n",
    "list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names\n",
    "no_imgs = []  # No. of samples per family\n",
    "for i in range(len(list_fams)):\n",
    "    os.chdir(list_fams[i])\n",
    "    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png'\n",
    "    no_imgs.append(len1)\n",
    "    os.chdir('..')\n",
    "num_samples = np.sum(no_imgs)  # total number of all samples\n",
    "\n",
    "# Compute the labels\n",
    "y = np.zeros(num_samples)\n",
    "pos = 0\n",
    "label = 0\n",
    "for i in no_imgs:\n",
    "    print (\"Label:%2d\\tFamily: %15s\\tNumber of images: %d\" % (label, list_fams[label], i))\n",
    "    for j in range(i):\n",
    "        y[pos] = label\n",
    "        pos += 1\n",
    "    label += 1\n",
    "num_classes = label\n",
    "\n",
    "# Compute the features\n",
    "width, height,channels = (224,224,3)\n",
    "X = np.zeros((num_samples, width, height, channels))\n",
    "cnt = 0\n",
    "list_paths = [] # List of image paths\n",
    "print(\"Processing images ...\")\n",
    "for i in range(len(list_fams)):\n",
    "    for img_file in image.list_pictures(list_fams[i], ext='jpg|jpeg|bmp|png'):\n",
    "        #print(\"[%d] Processing image: %s\" % (cnt, img_file))\n",
    "        list_paths.append(os.path.join(os.getcwd(),img_file))\n",
    "        img = image.load_img(img_file, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        X[cnt] = x\n",
    "        cnt += 1\n",
    "print(\"Images processed: %d\" %(cnt))\n",
    "\n",
    "os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding classes (y) into integers (y_encoded) and then generating one-hot-encoding (Y)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "Y = np_utils.to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating base model (VGG16 convolutional layers)\n",
    "image_shape = (224, 224, 3)                                                                                                                                               \n",
    "weights='weights-virussign-xception-Adam-100epochs-fromscratch.h5'\n",
    "model = Xception(weights=None, input_shape=image_shape, include_top=True, classes=num_classes)\n",
    "model.load_weights(weights)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility to search for layer index by name. \n",
    "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
    "layer_idx = utils.find_layer_idx(model, 'predictions')\n",
    "\n",
    "# https://github.com/raghakot/keras-vis/issues/53\n",
    "# \"You need to specify penultimate_layer_idx in this case.\n",
    "# By default, it will use the AveragePooling layer which does not have any spatial resolution.\n",
    "# Try using the layer above it which has a (7, 7) resolution.\"\n",
    "penultimate_layer_idx = utils.find_layer_idx(model, 'block14_sepconv2_act')\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = utils.apply_modifications(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samplesbyfamily = 10\n",
    "samplesbyrow = 5\n",
    "for fam in list_fams:\n",
    "    print(\"Family: %s\" %(fam))\n",
    "    fam_samples = [name for name in list_paths if fam in name]\n",
    "    image_paths = random.sample(fam_samples, samplesbyfamily)\n",
    "    \n",
    "    #fig = plt.figure(figsize=(16, 8))\n",
    "    f, ax = plt.subplots(samplesbyfamily//samplesbyrow, samplesbyrow)\n",
    "    f.set_size_inches(3*samplesbyrow, 3*(samplesbyfamily//samplesbyrow))\n",
    "    ind = 0\n",
    "    \n",
    "    for path in image_paths:        \n",
    "        img = io.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = image.img_to_array(img)\n",
    "        \n",
    "        x = image.load_img(path, target_size=(224, 224))\n",
    "        x = image.img_to_array(x)\n",
    "        x = preprocess_input(x)\n",
    "        pred_class = np.argmax(model.predict(np.array([x])))\n",
    "        pred_proba = np.amax(model.predict(np.array([x])))\n",
    "        print(\"Image: %s - Class: %s - Pred: %d (%s) - Prob: %.2f\" %(path.split('/')[-1:],path.split('/')[-2:-1],pred_class,list_fams[pred_class],pred_proba))\n",
    "        \n",
    "        heatmapguided = visualize_cam(model, layer_idx, filter_indices=[pred_class], seed_input=x, penultimate_layer_idx=penultimate_layer_idx)        \n",
    "        \n",
    "        ax[ind//samplesbyrow,ind%samplesbyrow].axis('off')\n",
    "        ax[ind//samplesbyrow,ind%samplesbyrow].imshow(overlay(heatmapguided, img))\n",
    "        ind = ind + 1\n",
    "        \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
